{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb5ac575",
   "metadata": {},
   "source": [
    "# Collect Normalized Attention\n",
    "- We extracted normalized attentions with following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e264928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "import nltk.translate.bleu_score as bleu\n",
    "import numpy as np\n",
    "import torch\n",
    "from diff_match_patch import diff_match_patch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers.tokenization_utils import PreTrainedTokenizer\n",
    "from transformers import set_seed,BatchEncoding\n",
    "set_seed(42)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from typing import Any, DefaultDict, List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa052631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from directory APR Models/codet5base_wildsmall_noabstract\n"
     ]
    }
   ],
   "source": [
    "args=argparse.Namespace(\n",
    "    batch_size=1, # do not change\n",
    "    size=\"small_noabstract\", \n",
    "    max_length = 256,\n",
    "    device = \"cuda\",\n",
    "    target_dataset=\"val\",\n",
    "    trgatt = \"cross\" \n",
    ")\n",
    "\n",
    "# Load APR Model\n",
    "load_model_dir = f\"APR Models/codet5base_wild{args.size}\"\n",
    "device = args.device\n",
    "tokenizer = RobertaTokenizer.from_pretrained(load_model_dir)\n",
    "model = T5ForConditionalGeneration.from_pretrained(load_model_dir, return_dict=True, output_attentions=True)\n",
    "model.to(args.device) \n",
    "model.eval()\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(f\"Loaded from directory {load_model_dir}\")\n",
    "\n",
    "#  Load dataset\n",
    "if 'noabstract' in args.size:\n",
    "    datasetdir = f\"Dataset/{args.size}\"\n",
    "    with open(f\"{datasetdir}/val.buggy-fixed.buggy\",\"r\",encoding='utf8') as f:\n",
    "        inputs = f.read().split('\\n')\n",
    "        inputs = [x for x in inputs if x!='']\n",
    "    with open(f\"{datasetdir}/val.buggy-fixed.fixed\",\"r\",encoding='utf8') as f:   \n",
    "        labels = f.read().split('\\n')\n",
    "        labels = [x for x in labels if x!='']\n",
    "    val_data = dict()\n",
    "    val_data['buggy']=inputs\n",
    "    val_data['fixed']=labels\n",
    "    \n",
    "    with open(f\"{datasetdir}/test.buggy-fixed.buggy\",\"r\",encoding='utf8') as f:\n",
    "        inputs = f.read().split('\\n')\n",
    "        inputs = [x for x in inputs if x!='']\n",
    "    with open(f\"{datasetdir}/test.buggy-fixed.fixed\",\"r\",encoding='utf8') as f:   \n",
    "        labels = f.read().split('\\n')\n",
    "        labels = [x for x in labels if x!='']\n",
    "    test_data = dict()\n",
    "    test_data['buggy']=inputs\n",
    "    test_data['fixed']=labels\n",
    "    \n",
    "else:\n",
    "    dataset = load_dataset(\"code_x_glue_cc_code_refinement\",args.size)\n",
    "    train_data = dataset.data['train']\n",
    "    val_data = dataset.data['validation']\n",
    "    test_data = dataset.data['test']\n",
    "    print(f\"#train: {train_data.num_rows}, #val: {val_data.num_rows}, #test: {test_data.num_rows}\")\n",
    "    print(val_data.column_names)\n",
    "\n",
    "    if args.target_dataset=='test':\n",
    "        inputs = test_data['buggy'].to_pylist()\n",
    "        labels = test_data['fixed'].to_pylist()\n",
    "        print(\"load test\")\n",
    "    elif args.target_dataset=='val':\n",
    "        inputs = val_data['buggy'].to_pylist()\n",
    "        labels = val_data['fixed'].to_pylist()\n",
    "        print(\"load val\")\n",
    "    elif args.target_dataset=='train':\n",
    "        inputs = train_data['buggy'].to_pylist()\n",
    "        labels = train_data['fixed'].to_pylist()\n",
    "        print(\"load train\")\n",
    "    else:\n",
    "        print(\"CHECK THE ARGS.TARGET_DATASET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42263ee3",
   "metadata": {},
   "source": [
    "# 1. Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5a1d28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of head: 12 number of layer: 12 attention dim: 64\n"
     ]
    }
   ],
   "source": [
    "def get_model_config():\n",
    "    model = T5ForConditionalGeneration.from_pretrained(load_model_dir, output_attentions=True,output_hidden_states=True)\n",
    "    number_of_heads = model.config.num_heads\n",
    "    number_of_layers = model.config.num_layers\n",
    "    attention_dimsize =  model.config.d_kv\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    return number_of_heads, number_of_layers, attention_dimsize\n",
    "\n",
    "number_of_heads, number_of_layers, attention_dim = get_model_config()\n",
    "print(\"number of head:\", number_of_heads, \"number of layer:\", number_of_layers, \"attention dim:\",attention_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cefcbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BugFixDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings: BatchEncoding, targets: BatchEncoding, idxs):\n",
    "        self.encodings = encodings\n",
    "        self.target_encodings = targets\n",
    "        self.idxs = idxs\n",
    "\n",
    "    def __getitem__(self, index: int) -> Dict[str, Any]:\n",
    "        item = {key: torch.tensor(val[index]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.target_encodings[\"input_ids\"][index], dtype=torch.long)\n",
    "        item[\"idx\"] = self.idxs[index]\n",
    "        return item\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "    \n",
    "def create_dataset(\n",
    "    idxs: List[int],\n",
    "    inputs: List[str],\n",
    "    labels: List[str],\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "    pad_truncate: bool,\n",
    "    max_length=None,\n",
    ") -> BugFixDataset:\n",
    "\n",
    "    input_encodings = tokenizer(\n",
    "        inputs, truncation=pad_truncate, padding=pad_truncate, max_length=max_length\n",
    "    )\n",
    "    label_encodings = tokenizer(\n",
    "        labels, truncation=pad_truncate, padding=pad_truncate, max_length=max_length\n",
    "    )\n",
    "\n",
    "    dataset = BugFixDataset(input_encodings, label_encodings, idxs)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45854f4",
   "metadata": {},
   "source": [
    "# Extract value vector and attention map to make normalized attention map\n",
    "- Results are saved in ExtractedAttentions folders\n",
    "- Same as the saved files in Attentions folders (we extracted in advance with following codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378160b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_beam_map(Amap, layer, head, beam_indices):\n",
    "    outmap = []\n",
    "    for step in range(len(beam_indices)): # output generation step\n",
    "        b = beam_indices[step]\n",
    "        att = Amap[step][layer][b][head][0] \n",
    "        outmap.append(att)\n",
    "    outmap = torch.stack(outmap)\n",
    "    return outmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3623bdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd8b0f0e14a4de9b66b4612fdf786f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5835 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t0\t3500\t7776\n"
     ]
    }
   ],
   "source": [
    "if args.target_dataset==\"val\":\n",
    "    inputs = val_data['buggy']\n",
    "    labels = val_data['fixed']\n",
    "elif args.target_dataset==\"test\":\n",
    "    inputs = test_data['buggy']\n",
    "    labels = test_data['fixed']\n",
    "\n",
    "resultsavedir = f\"ExtractedAttentions/codet5base_wildsmall_noabstract\"\n",
    "lhpairs = [(l,h) for l in range(number_of_layers) for h in range(number_of_heads)]\n",
    "\n",
    "# Dataloader\n",
    "idxs = np.arange(len(inputs))\n",
    "dataset = create_dataset(idxs, inputs, labels, tokenizer, pad_truncate=True)\n",
    "dataloader = DataLoader(dataset,batch_size=args.batch_size,shuffle=False,drop_last=False)\n",
    "\n",
    "pbar = tqdm(range(len(dataloader)))\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for batch in dataloader:\n",
    "    batch = {key:val.to(args.device) for key, val in batch.items()}\n",
    "    # 1. batch info\n",
    "    input_ids=batch['input_ids']\n",
    "    answer_ids = batch['labels']\n",
    "    idxs = batch['idx'].to('cpu').numpy()\n",
    "\n",
    "    # 2.  model output\n",
    "    key_outputs = model.generate(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'],\n",
    "                                num_beams=5, max_length=args.max_length, output_scores=True, return_dict_in_generate=True)\n",
    "    outputs = key_outputs['sequences'][:,1:] # remove start token\n",
    "\n",
    "    #  3. Value vectors saved during generation\n",
    "    l2vvecs = {}\n",
    "    for layer in range(number_of_layers):\n",
    "        if args.trgatt==\"encoder\":\n",
    "            vvecs = model.encoder.block[layer].layer[0].SelfAttention.vvecs\n",
    "        elif args.trgatt==\"decoder\":\n",
    "            vvecs = model.decoder.block[layer].layer[0].SelfAttention.vvecs\n",
    "        elif args.trgatt==\"cross\":\n",
    "            vvecs = model.decoder.block[layer].layer[1].EncDecAttention.vvecs\n",
    "        else:\n",
    "            print(\"Check args.trgatt\")\n",
    "        vvecs = vvecs.detach() #(batchsize, #head, #token, 64) value vector\n",
    "        l2vvecs[layer] = vvecs\n",
    "        \n",
    "    # 4. Beam indices\n",
    "    beam_indices = key_outputs.beam_indices[0]\n",
    "    beam_indices = beam_indices[:-1] # delete eos token\n",
    "\n",
    "    # 5. Organize I/O tokens\n",
    "    input_id = [x.item() for x in input_ids[0] if x.item()!=0][1:-1] # Remove eos, sos\n",
    "    output_id = [x.item() for x in outputs[0] if x.item()!=0][1:-1]\n",
    "    answer_id = [x.item() for x in answer_ids[0] if x.item()!=0][1:-1]\n",
    "    if output_id==answer_id:\n",
    "        em = 1\n",
    "    else:\n",
    "        em = 0\n",
    "\n",
    "    # 6. Make vector\n",
    "    results = []\n",
    "    total, changed = 0,0\n",
    "    for layer, head in lhpairs:\n",
    "        vvec = l2vvecs[layer][0][head] # Value vector of input tokens. All the same regardless of the beam. (0 is the place of the slected beam)\n",
    "        vvec = vvec[1:len(input_id)+1]\n",
    "        vnorms = torch.norm(vvec, dim=1)\n",
    "        \n",
    "        att_map = process_beam_map(key_outputs['cross_attentions'], layer, head, beam_indices) # Map stacked according to beam index\n",
    "        att_map = att_map[1:len(output_id)+1,1:len(input_id)+1]\n",
    "        \n",
    "        norm_map = att_map*vnorms\n",
    "        att_map = att_map.detach().to('cpu').numpy()\n",
    "        norm_map = norm_map.detach().to('cpu').numpy()\n",
    "        for row, norm_row in zip(att_map, norm_map):\n",
    "            total+=1\n",
    "            rank = np.argsort(row)[::-1]\n",
    "            normrank = np.argsort(norm_row)[::-1]\n",
    "            if rank[0]!=normrank[0]:\n",
    "                changed+=1\n",
    "        results.append([idxs[0], em, input_id, output_id, answer_id, layer, head, vnorms, att_map, norm_map])        \n",
    "    print(idxs[0], em, changed, total, sep='\\t')\n",
    "    fileidx = idxs[0]\n",
    "\n",
    "    with open(f\"{resultsavedir}/{fileidx}.pkl\",\"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "        \n",
    "    del results\n",
    "    torch.cuda.empty_cache()\n",
    "    pbar.update(1)\n",
    "    fileidx+=1\n",
    "    break # Remove comment to save all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b749857e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
